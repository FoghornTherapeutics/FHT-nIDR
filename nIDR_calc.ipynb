{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c3f6e1b-a4b9-4ee2-9c60-122704a398cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json \n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b19241-9007-43ac-ab46-82751ba5ab8c",
   "metadata": {},
   "source": [
    "# nIDR method with threshold computed from null distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d8e0571-918e-4a3d-8efe-e2302e606689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata_subdir exists:True\n",
      "\n",
      "PEAKS_dir exists:True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "experiment_id = \"NS-23.0061\"\n",
    "\n",
    "metadata_subdir = os.path.expanduser(\"~/fht.samba.data/experiments/ATACseq/{}/analysis/metadata/\".format(experiment_id))\n",
    "print('metadata_subdir exists:{}\\n'.format(os.path.exists(metadata_subdir)))\n",
    "\n",
    "PEAKS_dir = os.path.expanduser(\"~/fht.samba.data/experiments/ATACseq/{}/alignment/macs2/\".format(experiment_id))\n",
    "print('PEAKS_dir exists:{}\\n'.format(os.path.exists(PEAKS_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ddcd823-8eb2-4428-98e7-b8754eaba019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(name_dir):\n",
    "    if os.path.exists(name_dir):\n",
    "        shutil.rmtree(name_dir)\n",
    "    os.mkdir(name_dir)\n",
    "    return name_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9b855bf-9cd7-4bb6-8c4e-e2dcd99bb04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../merged_narrowPeak/\n",
      "../idr_bed/\n"
     ]
    }
   ],
   "source": [
    "merged_narrowPeak_dir = create_dir(name_dir = '../merged_narrowPeak/')\n",
    "print(merged_narrowPeak_dir)\n",
    "    \n",
    "idr_bed_dir = create_dir(name_dir = '../idr_bed/')\n",
    "print(idr_bed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a263457c-c778-4c55-aa79-fd5528ce8d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_filename : NS-23.0061_group_dict.json\n",
      "output_filepath : /home/fuzan/fht.samba.data/experiments/ATACseq/NS-23.0061/analysis/metadata/NS-23.0061_group_dict.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'WT_HCT116': ['SRR5876158', 'SRR5876159'],\n",
       " 'ARID1BKD_HCT116': ['SRR5876160', 'SRR5876161'],\n",
       " 'ARID1AKO_HCT116': ['SRR5876162', 'SRR5876163'],\n",
       " 'ARID1AKO_ARID1BKD_HCT116': ['SRR5876164', 'SRR5876165'],\n",
       " 'WT_TOV21G': ['SRR5876661', 'SRR5876662'],\n",
       " 'ARID1BKD_TOV21G': ['SRR5876663', 'SRR5876664']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_group_dict(metadata_subdir, experiment_id): \n",
    "    output_filename = experiment_id + '_group_dict.json'\n",
    "    print(\"output_filename : {}\".format(output_filename))\n",
    "\n",
    "    output_filepath = os.path.join(metadata_subdir, output_filename)\n",
    "    print(\"output_filepath : {}\".format(output_filepath))\n",
    "    \n",
    "    # Opening JSON file\n",
    "    with open(output_filepath) as json_file:\n",
    "        contrast_dict = json.load(json_file)\n",
    "        \n",
    "    return contrast_dict\n",
    "\n",
    "group_dict = read_group_dict(metadata_subdir, experiment_id)\n",
    "group_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e4c2a56-d340-4a10-864a-dd810ec4d81e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_narrowPeak_files(group):    \n",
    "\n",
    "    # write path of each narrowPeak file\n",
    "    narrowPeak_list = [PEAKS_dir + s + '_peaks.narrowPeak' for s in group_dict[group]]\n",
    "\n",
    "    # define variable name for each replicate file\n",
    "    narrowPeak_list_bash = '\\t'.join(narrowPeak_list)\n",
    "    \n",
    "    # combined 3 replicates\n",
    "    !grep -h '^chr'  {narrowPeak_list_bash} > {merged_narrowPeak_dir}{group}.combined.narrowPeak\n",
    "\n",
    "    # sort reads by chromosome coordinates\n",
    "    !sort -k1,1V -k2,2n -k3,3n {merged_narrowPeak_dir}{group}.combined.narrowPeak > {merged_narrowPeak_dir}{group}.sorted.narrowPeak\n",
    "\n",
    "    # bedtools merge reads\n",
    "    !bedtools merge -d 50 -c 4,8 -o collapse,collapse -delim \"|\" -i {merged_narrowPeak_dir}{group}.sorted.narrowPeak > {merged_narrowPeak_dir}{group}.all_merged.narrowPeak\n",
    "\n",
    "    # reformat replicate column\n",
    "    cmd_format = \"\"\"awk '{{ gsub(/_peak_[a-z0-9]*/, \"\", $4) }}1' {merged_narrowPeak_dir}{group}.all_merged.narrowPeak >  {merged_narrowPeak_dir}{group}.merged.narrowPeak\"\"\".format(merged_narrowPeak_dir=merged_narrowPeak_dir, group=group)\n",
    "    ! {cmd_format}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7861ae3-2adb-4a3b-87a0-a98a6b5cd09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_pivot_merged_narrowPeak_mean(merged_narrowPeak_dir, group):\n",
    "    #  Read merged dataframe + format\n",
    "    merged_narrowPeak = pd.read_table(merged_narrowPeak_dir + group + '.merged.narrowPeak', delimiter = ' ', header=None)\n",
    "    merged_narrowPeak.columns = ['chr', 'start', 'end', 'peak', 'logFC']\n",
    "    merged_narrowPeak['peak_id'] = merged_narrowPeak['chr'] + ':'+ merged_narrowPeak['start'].astype('str')  + '-' + merged_narrowPeak['end'].astype('str')\n",
    "    merged_narrowPeak.set_index(\"peak_id\", inplace = True)\n",
    "\n",
    "    # split peak_id and logFC\n",
    "    merged_narrowPeak[\"peak_split\"] = merged_narrowPeak.peak.str.split(\"|\")\n",
    "    merged_narrowPeak[\"logFC_split\"] = merged_narrowPeak.logFC.str.split(\"|\")\n",
    "\n",
    "    # create one column with peak_id and logFC tuple\n",
    "    merged_narrowPeak[\"peak_logFC_zip\"] = merged_narrowPeak.apply(lambda row: list(zip(row.peak_split, row.logFC_split)), axis=1)\n",
    "\n",
    "    # create a row for each tuple\n",
    "    long_merged_narrowPeak = merged_narrowPeak[[\"chr\", \"start\", \"end\", \"peak_logFC_zip\"]].explode(\"peak_logFC_zip\")\n",
    "\n",
    "    # split tuples into two columns\n",
    "    long_merged_narrowPeak[\"sample_ID\"] = [x[0] for x in long_merged_narrowPeak.peak_logFC_zip]\n",
    "    long_merged_narrowPeak[\"logFC\"] = [float(x[1]) for x in long_merged_narrowPeak.peak_logFC_zip]\n",
    "\n",
    "    # compute mean of logFC for each peak_id and replicate\n",
    "    merged_narrowPeak_mean = long_merged_narrowPeak.reset_index().drop(\"peak_logFC_zip\", axis=1).groupby([\"peak_id\", \"chr\", \"start\", \"end\", \"sample_ID\"], sort=False).mean().reset_index().set_index(\"peak_id\")\n",
    "\n",
    "    # pivot sample_id column into three columns\n",
    "    pivot_merged_narrowPeak_mean= merged_narrowPeak_mean[[\"logFC\", \"sample_ID\"]].reset_index().pivot(index=\"peak_id\", columns=\"sample_ID\", values=\"logFC\").fillna(0)\n",
    "    \n",
    "    return  merged_narrowPeak_mean, pivot_merged_narrowPeak_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0a1e257-23d6-4e47-88e7-7e0f5c0ad990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shuffled_min_perc_rank(pivot_merged_narrowPeak_mean):\n",
    "    shuffled_pivot_merged_narrowPeak_mean = pivot_merged_narrowPeak_mean.copy()#.sample(frac = 1, axis=0)\n",
    "    for col in shuffled_pivot_merged_narrowPeak_mean.columns:\n",
    "        t = shuffled_pivot_merged_narrowPeak_mean[col].to_numpy()\n",
    "        np.random.shuffle(t)\n",
    "        shuffled_pivot_merged_narrowPeak_mean[col] = t\n",
    "    \n",
    "    # compute min of percentage rank of mean for each replicate\n",
    "    shuffled_min_perc_rank =  shuffled_pivot_merged_narrowPeak_mean.rank(pct=True, axis=0).min(axis=1)\n",
    "    return shuffled_min_perc_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b221382-ea06-4d4c-8715-d7b2fb2161d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_threshold(shuffled_min_perc_rank, group):\n",
    "    shuffled_sorted_min_perc_rank = shuffled_min_perc_rank.iloc[::10].sort_values()   \n",
    "    # fig = px.ecdf(shuffled_sorted_min_perc_rank)\n",
    "    shuffled_overall_min_perc_rank = np.linspace(0., 1., num=shuffled_sorted_min_perc_rank.shape[0])\n",
    "\n",
    "    # find index from shuffled_sorted_min_perc_rank that has the closest number to .9 in shuffled_overall_min_perc_rank \n",
    "    index = np.argmin(np.abs(np.array(shuffled_overall_min_perc_rank)-.9))\n",
    "    threshold = shuffled_sorted_min_perc_rank[index]\n",
    "    print('\\n% of rank min the closest to 0.9: \\n{}'.format(shuffled_overall_min_perc_rank[index]))\n",
    "    print('\\nrank min corresponding to 10% of kept reads, i.e. new threshold: \\n{}'.format(threshold))\n",
    "    \n",
    "    # fig = px.scatter(x=shuffled_sorted_min_perc_rank,y=shuffled_overall_min_perc_rank, title=group)\n",
    "    # fig.add_vline(x=threshold,  line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "    # fig.show()\n",
    "    \n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b593141c-5bb2-450d-bb87-f0ddc0322f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_merged_narrowPeak(pivot_merged_narrowPeak_mean, merged_narrowPeak_mean, threshold, group):\n",
    "    # compute min of percentage rank of mean for each replicate\n",
    "    min_perc_rank =  pivot_merged_narrowPeak_mean.rank(pct=True, axis=0).min(axis=1)\n",
    "    \n",
    "    # # plot ECDF\n",
    "    # sorted_min_perc_rank = min_perc_rank.iloc[::10].sort_values()\n",
    "    # overall_min_perc_rank = np.linspace(0., 1., num=sorted_min_perc_rank.shape[0])\n",
    "    # fig = px.scatter(x=sorted_min_perc_rank,y=overall_min_perc_rank, title=group)\n",
    "    # fig.add_vline(x=threshold,  line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "    # fig.show()\n",
    "\n",
    "    # get list of peaks that we keep (min rank > threshold)\n",
    "    keep_peaks = min_perc_rank.index[min_perc_rank > threshold]\n",
    "\n",
    "    # filter narrowPeak with list of peaks\n",
    "    filt_IDR_narrowPeak = merged_narrowPeak_mean.loc[keep_peaks]\n",
    "\n",
    "    # drop sample_ID and logFC columns to delete duplicated peak_id\n",
    "    filt_IDR_narrowPeak.drop(['sample_ID', 'logFC'], axis=1, inplace=True)\n",
    "\n",
    "    # remove duplicates\n",
    "    filt_IDR_narrowPeak.drop_duplicates(inplace=True)\n",
    "    \n",
    "    print(\"pivot_merged_narrowPeak_mean.shape:  {}\".format(pivot_merged_narrowPeak_mean.shape))\n",
    "    print(\"filt_IDR_narrowPeak.shape:  {}\".format(filt_IDR_narrowPeak.shape))\n",
    "    return filt_IDR_narrowPeak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b519bbb-3b41-48ef-ba90-a31db23f2afd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_list: ['WT_HCT116', 'ARID1BKD_HCT116', 'ARID1AKO_HCT116', 'ARID1AKO_ARID1BKD_HCT116', 'WT_TOV21G', 'ARID1BKD_TOV21G']\n",
      "\n",
      "group: WT_HCT116\n",
      "\n",
      "% of rank min the closest to 0.9: \n",
      "0.8999999999999999\n",
      "\n",
      "rank min corresponding to 10% of kept reads, i.e. new threshold: \n",
      "0.6519628042192422\n",
      "pivot_merged_narrowPeak_mean.shape:  (308207, 2)\n",
      "filt_IDR_narrowPeak.shape:  (60489, 3)\n",
      "\n",
      "group: ARID1BKD_HCT116\n",
      "\n",
      "% of rank min the closest to 0.9: \n",
      "0.9000052532044547\n",
      "\n",
      "rank min corresponding to 10% of kept reads, i.e. new threshold: \n",
      "0.6815840621963071\n",
      "pivot_merged_narrowPeak_mean.shape:  (380730, 2)\n",
      "filt_IDR_narrowPeak.shape:  (68550, 3)\n",
      "\n",
      "group: ARID1AKO_HCT116\n",
      "\n",
      "% of rank min the closest to 0.9: \n",
      "0.9\n",
      "\n",
      "rank min corresponding to 10% of kept reads, i.e. new threshold: \n",
      "0.717031717106752\n",
      "pivot_merged_narrowPeak_mean.shape:  (419805, 2)\n",
      "filt_IDR_narrowPeak.shape:  (60139, 3)\n",
      "\n",
      "group: ARID1AKO_ARID1BKD_HCT116\n",
      "\n",
      "% of rank min the closest to 0.9: \n",
      "0.8999899989999001\n",
      "\n",
      "rank min corresponding to 10% of kept reads, i.e. new threshold: \n",
      "0.674779043166277\n",
      "pivot_merged_narrowPeak_mean.shape:  (399965, 2)\n",
      "filt_IDR_narrowPeak.shape:  (56801, 3)\n",
      "\n",
      "group: WT_TOV21G\n",
      "\n",
      "% of rank min the closest to 0.9: \n",
      "0.8999934735788718\n",
      "\n",
      "rank min corresponding to 10% of kept reads, i.e. new threshold: \n",
      "0.6768980595196659\n",
      "pivot_merged_narrowPeak_mean.shape:  (459680, 2)\n",
      "filt_IDR_narrowPeak.shape:  (43992, 3)\n",
      "\n",
      "group: ARID1BKD_TOV21G\n",
      "\n",
      "% of rank min the closest to 0.9: \n",
      "0.8999907123618465\n",
      "\n",
      "rank min corresponding to 10% of kept reads, i.e. new threshold: \n",
      "0.6783361226843897\n",
      "pivot_merged_narrowPeak_mean.shape:  (538357, 2)\n",
      "filt_IDR_narrowPeak.shape:  (53627, 3)\n"
     ]
    }
   ],
   "source": [
    "def create_narrowPeak(group_dict):\n",
    "    \n",
    "    group_list = list(group_dict.keys())\n",
    "    print('group_list: {}'.format(group_list))\n",
    "\n",
    "    for group in group_list:\n",
    "\n",
    "        print('\\ngroup: {}'.format(group))\n",
    "        \n",
    "        combine_narrowPeak_files(group)\n",
    "        merged_narrowPeak_mean, pivot_merged_narrowPeak_mean = format_pivot_merged_narrowPeak_mean(merged_narrowPeak_dir, group)\n",
    "        shuffled_min_perc_rank = generate_shuffled_min_perc_rank(pivot_merged_narrowPeak_mean)\n",
    "        threshold = compute_threshold(shuffled_min_perc_rank, group)\n",
    "        filt_IDR_narrowPeak = filter_merged_narrowPeak(pivot_merged_narrowPeak_mean, merged_narrowPeak_mean, threshold, group)\n",
    "        \n",
    "        # Plot ECDF\n",
    "        shuffled_sorted_min_perc_rank = shuffled_min_perc_rank.iloc[::10].sort_values()\n",
    "        shuffled_overall_min_perc_rank = np.linspace(0., 1., num=shuffled_sorted_min_perc_rank.shape[0])\n",
    "        fig = px.scatter(x=shuffled_sorted_min_perc_rank,y=shuffled_overall_min_perc_rank, title=group)\n",
    "        fig.add_vline(x=threshold,  line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "\n",
    "\n",
    "        min_perc_rank =  pivot_merged_narrowPeak_mean.rank(pct=True, axis=0).min(axis=1)\n",
    "        sorted_min_perc_rank = min_perc_rank.iloc[::10].sort_values()\n",
    "        overall_min_perc_rank = np.linspace(0., 1., num=sorted_min_perc_rank.shape[0])\n",
    "        fig.add_scatter(x=sorted_min_perc_rank, y=overall_min_perc_rank, mode=\"markers\", name=\"real\")\n",
    "        fig.update_layout(xaxis_title='min percent rank')\n",
    "        fig.update_layout(yaxis_title='% of peaks')\n",
    "        # fig.show()\n",
    "\n",
    "        # export as static image\n",
    "        pio.write_image(fig, merged_narrowPeak_dir + group + \"_ECDF.png\")\n",
    "                \n",
    "        # Save IDR narrowPeak\n",
    "        filt_IDR_narrowPeak.to_csv(idr_bed_dir + group + '.IDR.narrowPeak', sep=\"\\t\", index=None, header=None)\n",
    "        \n",
    "create_narrowPeak(group_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414df9e3-3805-495e-aa82-e83640e00b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e05d2d-1911-4ca8-9fbd-804855c71f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e3579-515e-4baf-bd8a-e596a32722ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49cc8c3-2211-4e55-9bd5-d107d3bfcce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e7ddeb-8c35-4c84-bc16-845137f504e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f67de3-3cd4-41b8-8c68-2f9661a134c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd632a93-e34b-4561-8e2a-5788888408d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd065c0-bbd0-40f6-b4f8-1981f47f3834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604eee69-fd38-4570-8681-3d89855aa893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94e97bd-9db8-4fc5-b611-6dbbe9dfd480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6179bd85-3440-438d-bb70-1bcc2e231720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c582724-1c7d-44e4-a502-9fc4ec08510e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e50b9cb-ca9a-4db0-8a73-8a7858aef603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634efb57-e68e-4855-83d8-96d053f41fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5bc24-ee9a-4c6f-874f-2feaed48837e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
